algorithm: ppo # Algorithm to use

policy: # Settings for the policy. See also, https://github.com/leggedrobotics/rsl_rl
  activation: elu # Activation function for the policy network
  actor_hidden_dims: [756, 512, 256] # Hidden dimensions for the actor network
  critic_hidden_dims: [756, 512, 256] # Hidden dimensions for the critic network
  init_noise_std: 1.0 # Initial noise standard deviation
  class_name: ActorCritic # Loading the ActorCritic class

runner:
  experiment_name: atlas_walking # Name of the experiment
  checkpoint: -1 # Checkpoint to load, -1 means the latest checkpoint
  load_run: -1 # Load run number, -1 means the latest run
  log_interval: 1 # Interval for logging
  max_iterations: 101 # Maximum number of iterations

runner_class_name: OnPolicyRunner # Class name for the runner. See also, https://github.com/leggedrobotics/rsl_rl
